{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "vm_tqYnLfcms"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import numpy as np\n",
        "from keras.utils import get_file\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import schedules\n",
        "from tensorflow.keras.applications import vgg19\n",
        "from keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import vgg19\n",
        "from keras.utils import plot_model\n",
        "from keras import Model\n",
        "import streamlit as st\n",
        "\n",
        "st.set_page_config(page_title=\"Neural Style Transfer\")\n",
        "st.title('Welcome to Neural Style Transfer')\n",
        "\n",
        "st.subheader(\"Choose Images\")\n",
        "# Loading of images\n",
        "style = st.file_uploader(\"Select Style Image\", type=[\"png\",\"jpg\",\"jpeg\"], key=\"style_img\")\n",
        "content = st.file_uploader(\"Select Content Image\", type=[\"png\",\"jpg\",\"jpeg\"], key=\"content_img\")\n",
        "\n",
        "if style is not None:\n",
        "    # To See details\n",
        "    file_details = {\"filename\":style.name, \"filetype\":style.type, \"filesize\":style.size}\n",
        "    # st.write(file_details)\n",
        "\n",
        "    # To View Uploaded Image\n",
        "    st.write(\"Style Image\")\n",
        "    st.image(style,width=500)\n",
        "\n",
        "    with open(style.name,\"wb\") as f:\n",
        "        f.write((style).getbuffer())\n",
        "    style_image_path = style.name\n",
        "\n",
        "\n",
        "if content is not None:\n",
        "    # To See details\n",
        "    file_details = {\"filename\":content.name, \"filetype\":content.type, \"filesize\":content.size}\n",
        "    # st.write(file_details)\n",
        "\n",
        "    # To View Uploaded Image\n",
        "    st.write(\"Content Image\")\n",
        "    st.image(content,width=500)\n",
        "\n",
        "    with open(content.name,\"wb\") as f:\n",
        "        f.write((content).getbuffer())\n",
        "    base_image_path = content.name\n",
        "\n",
        "hide_img_fs = '''\n",
        "<style>\n",
        "button[title=\"View fullscreen\"]{\n",
        "    visibility: hidden;}\n",
        "</style>\n",
        "'''\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    # Util function to open, resize and format pictures into appropriate tensors\n",
        "    img =load_img(\n",
        "        image_path, target_size=(img_nrows, img_ncols)\n",
        "    )\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return tf.convert_to_tensor(img)\n",
        "\n",
        "def gram_matrix(x):\n",
        "    x = tf.transpose(x, (2, 0, 1))\n",
        "    features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "    gram = tf.matmul(features, tf.transpose(features))\n",
        "    return gram\n",
        "\n",
        "def content_loss(base, combination):\n",
        "    return tf.reduce_sum(tf.square(combination - base))\n",
        "\n",
        "model = vgg19.VGG19(weights=\"imagenet\", include_top=False)\n",
        "\n",
        "outputs_dict= dict([(layer.name, layer.output) for layer in model.layers])\n",
        "feature_extractor = Model(inputs=model.inputs, outputs=outputs_dict)\n",
        "\n",
        "style_cnn = [\n",
        "    \"block1_conv1\",\n",
        "    \"block2_conv1\",\n",
        "    \"block3_conv1\",\n",
        "    \"block4_conv1\",\n",
        "    \"block5_conv1\",\n",
        "]\n",
        "\n",
        "content_cnn = \"block5_conv2\"\n",
        "\n",
        "content_weight = 2.5e-8\n",
        "style_weight = 1e-6\n",
        "\n",
        "def loss_function(combination_image, base_image, style_reference_image):\n",
        "\n",
        "    # 1. Combine all the images in the same tensioner.\n",
        "    input_tensor = tf.concat(\n",
        "        [base_image, style_reference_image, combination_image], axis=0\n",
        "    )\n",
        "\n",
        "    # 2. Get the values in all the layers for the three images.\n",
        "    features = feature_extractor(input_tensor)\n",
        "\n",
        "    #3. Inicializar the loss\n",
        "\n",
        "    loss = tf.zeros(shape=())\n",
        "\n",
        "    # 4. Extract the content layers + content loss\n",
        "    layer_features = features[content_cnn]\n",
        "    base_image_features = layer_features[0, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "\n",
        "    loss = loss + content_weight * content_loss(\n",
        "        base_image_features, combination_features\n",
        "    )\n",
        "    # 5. Extraer the style layers + style loss\n",
        "    for layer_name in style_cnn:\n",
        "        layer_features = features[layer_name]\n",
        "        style_reference_features = layer_features[1, :, :, :]\n",
        "        combination_features = layer_features[2, :, :, :]\n",
        "        sl = style_loss(style_reference_features, combination_features)\n",
        "        loss += (style_weight / len(style_cnn)) * sl\n",
        "\n",
        "    return loss\n",
        "\n",
        "@tf.function\n",
        "def compute_loss_and_grads(combination_image, base_image, style_reference_image):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_function(combination_image, base_image, style_reference_image)\n",
        "    grads = tape.gradient(loss, combination_image)\n",
        "    return loss, grads\n",
        "\n",
        "def result_saver(i):\n",
        "  # Create name\n",
        "  image_name = 'At_'+ str(i) + '_Iteration.png'\n",
        "\n",
        "  # Save image\n",
        "  img = deprocess_image(combination_image.numpy())\n",
        "  keras.preprocessing.image.save_img(image_name, img)\n",
        "\n",
        "optimizer = SGD(\n",
        "    keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "def run_style_transfer(iteration):\n",
        "  for i in range(1, iterations + 1):\n",
        "      loss, grads = compute_loss_and_grads(\n",
        "          combination_image, base_image, style_reference_image\n",
        "      )\n",
        "      optimizer.apply_gradients([(grads, combination_image)])\n",
        "      if i % 10 == 0:\n",
        "          print(\"Iteration %d: loss=%.2f\" % (i, loss))\n",
        "          result_saver(i)\n",
        "          scaled_value = ((i - 1) / (iterations - 1)) * (100 - 0) + 0\n",
        "          my_bar.progress(int(scaled_value), text=progress_text)\n",
        "  return True\n",
        "\n",
        "def style_loss(style, combination):\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n",
        "\n",
        "def deprocess_image(x):\n",
        "\n",
        "    # Convert the tensor into Array\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "\n",
        "    # We ensure that they do not have an average of 0\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "\n",
        "    # convert from BGR to RGB\n",
        "    x = x[:, :, ::-1]\n",
        "\n",
        "    # Ensure that they are between 0 and 255\n",
        "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
        "\n",
        "    return x\n",
        "\n",
        "st.markdown(hide_img_fs, unsafe_allow_html=True)\n",
        "\n",
        "if style is not None and content is not None:\n",
        "    img_nrows = 400\n",
        "    width, height = load_img(base_image_path).size\n",
        "    img_ncols = int(width * img_nrows / height)\n",
        "    base_image = preprocess_image(base_image_path)\n",
        "    style_reference_image = preprocess_image(style_image_path)\n",
        "    combination_image = tf.Variable(preprocess_image(base_image_path))\n",
        "    iterations = st.slider('Select the iterations?', 0, 400, 50, 20)\n",
        "    if st.button(\"Run\"):\n",
        "        progress_text = \"Operation in progress. Please wait.\"\n",
        "        my_bar = st.progress(0, text=progress_text)\n",
        "        val = run_style_transfer(iterations)\n",
        "        if val:\n",
        "            st.write(\"Output Image at 10 Iteration\")\n",
        "            st.image(\"At_10_Iteration.png\",width=500)\n",
        "            st.write(\"Output Image at \"+str(iterations)+\" Iteration\")\n",
        "            st.image(\"At_\"+str(iterations)+\"_Iteration.png\",width=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8NYyLbrfhod",
        "outputId": "e2a7bccf-c22e-4480-e929-fd16b29cf773"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"Your Token\")\n",
        "!nohup streamlit run app.py --server.port 80 &\n",
        "url = ngrok.connect('80')\n",
        "print(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_RyU5j6h--4",
        "outputId": "208e0cdb-c08a-41a0-875c-9a5a5524f5c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-06-16T15:37:59+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://ec74-34-126-177-84.ngrok-free.app\" -> \"http://localhost:80\"\n"
          ]
        }
      ]
    }
  ]
}